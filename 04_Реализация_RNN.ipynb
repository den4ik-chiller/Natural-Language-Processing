{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCUVOpfXuTwu"
      },
      "source": [
        "# Задание 1. Решите задачу расшифровки сообщения с помощью RNN. Представьте, что вам даны сообщения, зашифрованные с помощью шифра Цезаря, являющимся одним из самый простых шифров, в криптографии.\n",
        "Шифр цезаря работает следующим образом: каждая буква исходного алфавита сдвигается на K символов вправо:\n",
        "Пусть нам дано сообщение: message=\"RNN IS NOT AI\", тогда наше шифрование выполняющиеся по правилу f, с K=2, даст нам результат: f(message, K) = TPPAKUAPQVACK.\n",
        "Для удобства можно взять символы только одного регистра в нашей имплементации, и сказать, что все буквы не английского алфавита будут отмечены как прочерк \"-\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1eytTnkuWbS"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HzgwNSVuvc6"
      },
      "outputs": [],
      "source": [
        "# Определим ключ и словарь\n",
        "key = 2\n",
        "vocab = [char for char in ' -ABCDEFGHIJKLMNOPQRSTUVWXYZ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAZD5zTNux3D",
        "outputId": "fbe8536e-9f2d-4d26-99ee-afe44c3105db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TPPAKUAPQVACK\n"
          ]
        }
      ],
      "source": [
        "# Напишем функцию, которая делает\n",
        "def encrypt(text, key):\n",
        "    \"\"\"Returns the encrypted form of 'text'.\"\"\"\n",
        "    indexes = [vocab.index(char) for char in text]\n",
        "    encrypted_indexes = [(idx + key) % len(vocab) for idx in indexes]\n",
        "    encrypted_chars = [vocab[idx] for idx in encrypted_indexes]\n",
        "    encrypted = ''.join(encrypted_chars)\n",
        "    return encrypted\n",
        "\n",
        "print(encrypt('RNN IS NOT AI', key))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaCXyN2GvAXl"
      },
      "source": [
        "Теперь нам необходимо нагенерировать датасет для решения задачи обучения с учителем. Нашим датасетом может быть случайно зашифрованные фразы, и тогда его структура будет следующей: message --- encrypted message\n",
        "\n",
        "Это пример параллельного корпуса из НЛП.\n",
        "\n",
        "Но нам необходимо представить каждую букву в виде ее номера в словаре, чтобы далее воспользоваться Embedding слоем.\n",
        "\n",
        "Для простоты давайте допустим, что все строки имеют одинаковую длину seq_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ro6hjAvWu0gS"
      },
      "outputs": [],
      "source": [
        "num_examples = 256 # размер датасета\n",
        "seq_len = 18 # максимальная длина строки\n",
        "\n",
        "\n",
        "def encrypted_dataset(dataset_len, k):\n",
        "    \"\"\"\n",
        "    Return: List(Tuple(Tensor encrypted, Tensor source))\n",
        "    \"\"\"\n",
        "    dataset = []\n",
        "    for x in range(dataset_len):\n",
        "        random_message  = ''.join([random.choice(vocab) for x in range(seq_len)])\n",
        "        encrypt_random_message = encrypt(''.join(random_message), k)\n",
        "        src = [vocab.index(x) for x in random_message]\n",
        "        tgt = [vocab.index(x) for x in encrypt_random_message]\n",
        "        dataset.append([torch.tensor(tgt), torch.tensor(src)])\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g0dmDshvoW6"
      },
      "source": [
        "**Pytorch RNN:**\n",
        "$$h_t = \\text{tanh}(w_{ih} x_t + b_{ih} + w_{hh} h_{(t-1)} + b_{hh})$$\n",
        "\n",
        "**where : $h_t$ is the hidden state at time $t$, $x_t$ is\n",
        "    the input at time $t$, and $h_{(t-1)}$ is the hidden state of the\n",
        "    previous layer at time $t-1$ or the initial hidden state at time $0$.**\n",
        "    \n",
        "Args:\n",
        "\n",
        "        input_size: The number of expected features in the input $x$\n",
        "        hidden_size: The number of features in the hidden state $h$\n",
        "        num_layers: Number of recurrent layers. E.g., setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrA91YDVvLXf"
      },
      "outputs": [],
      "source": [
        "class Decipher(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim,\n",
        "                 rnn_type='simple'):\n",
        "        \"\"\"\n",
        "        :params: int vocab_size\n",
        "        :params: int embedding_dim\n",
        "        :params\n",
        "        \"\"\"\n",
        "        super(Decipher, self).__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embedding_dim)\n",
        "        if rnn_type == 'simple':\n",
        "            self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers = 2)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "        self.initial_hidden = torch.zeros(2, 1, hidden_dim)\n",
        "\n",
        "\n",
        "    def forward(self, cipher):\n",
        "        # CHECK INPUT SIZE\n",
        "        # Unsqueeze 1 dimension for batches\n",
        "        embd_x = self.embed(cipher).unsqueeze(1)\n",
        "        out_rnn, hidden = self.rnn(embd_x, self.initial_hidden)\n",
        "        # Apply the affine transform and transpose output in appropriate way\n",
        "        # because you want to get the softmax on vocabulary dimension\n",
        "        # in order to get probability of every letter\n",
        "        return self.fc(out_rnn).transpose(1, 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZ86nE9AvyA4"
      },
      "outputs": [],
      "source": [
        "# определим параметры нашей модели\n",
        "embedding_dim = 5\n",
        "hidden_dim = 10\n",
        "vocab_size = len(vocab)\n",
        "lr = 1e-3\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Инициализируйте модель\n",
        "model = Decipher(vocab_size, embedding_dim, hidden_dim)\n",
        "\n",
        "# Инициализируйте оптимизатор: рекомендуется Adam\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T8mvUqoyw_x",
        "outputId": "0fd5c7e3-3c4b-489e-8cd5-7582c4ea45c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[' ', '-', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
          ]
        }
      ],
      "source": [
        "print(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFgvsEaPv3eR",
        "outputId": "07aa593c-8f91-4ed8-f442-a679b8ca6f0a",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Loss: 2.7386\n",
            "Accuracy: 24.83%\n",
            "Epoch: 1\n",
            "Loss: 1.9151\n",
            "Accuracy: 58.25%\n",
            "Epoch: 2\n",
            "Loss: 1.2349\n",
            "Accuracy: 81.16%\n",
            "Epoch: 3\n",
            "Loss: 1.0288\n",
            "Accuracy: 92.32%\n",
            "Epoch: 4\n",
            "Loss: 0.7506\n",
            "Accuracy: 96.31%\n",
            "Epoch: 5\n",
            "Loss: 0.5291\n",
            "Accuracy: 99.89%\n",
            "Epoch: 6\n",
            "Loss: 0.2981\n",
            "Accuracy: 100.00%\n",
            "Epoch: 7\n",
            "Loss: 0.3077\n",
            "Accuracy: 100.00%\n",
            "Epoch: 8\n",
            "Loss: 0.1889\n",
            "Accuracy: 100.00%\n",
            "Epoch: 9\n",
            "Loss: 0.1631\n",
            "Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "k = 10\n",
        "for x in range(num_epochs):\n",
        "    print('Epoch: {}'.format(x))\n",
        "    for encrypted, original in encrypted_dataset(num_examples, k):\n",
        "        scores = model(encrypted)\n",
        "        original = original.unsqueeze(1)\n",
        "        # Calculate loss\n",
        "        loss = criterion(scores, original)\n",
        "        # Zero grads\n",
        "        optimizer.zero_grad()\n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "    print('Loss: {:6.4f}'.format(loss.item()))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        matches, total = 0, 0\n",
        "        for encrypted, original in encrypted_dataset(num_examples, k):\n",
        "            # Compute a softmax over the outputs\n",
        "            predictions = F.softmax(model(encrypted), 1)\n",
        "            # Choose the character with the maximum probability (greedy decoding)\n",
        "            _, batch_out = predictions.max(dim=1)\n",
        "            # Remove batch\n",
        "            batch_out = batch_out.squeeze(1)\n",
        "            # Calculate accuracy\n",
        "            matches += torch.eq(batch_out, original).sum().item()\n",
        "            total += torch.numel(batch_out)\n",
        "        accuracy = matches / total\n",
        "        print('Accuracy: {:4.2f}%'.format(accuracy * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZIRpzhKFiOT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}